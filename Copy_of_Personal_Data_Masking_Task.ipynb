{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbFRPDKTvlSY"
      },
      "source": [
        "## Setup\n",
        "First, let's set up our environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvlrkKEu_8V-",
        "outputId": "79e41e67-f7b4-468d-8f3c-f6e23474de70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyDNQy4Uv7TT"
      },
      "source": [
        "Now, import the required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "INh9sxvSAUKd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZCR01uewB70"
      },
      "source": [
        "### Setting up the OpenAI API Key\n",
        "Before proceeding with the assignment, you'll need to obtain an OpenAI API key. This key is essential for authenticating your requests to the OpenAI API. Here's how to get started:\n",
        "\n",
        "1. Go to https://platform.openai.com/signup\n",
        "1. Click on \"Sign up\" and follow the registration process\n",
        "1. Once logged in, navigate to the https://platform.openai.com/api-keys\n",
        "1. You may need to provide additional information or verify your account\n",
        "1. Generate a new key and make sure to copy it immediately (you won't be able to see it again)\n",
        "1. New accounts typically receive $5 of free credit from OpenAI. This should be sufficient for completing this assignment\n",
        "\n",
        "> **Important:** If you're unable to obtain an API key for any reason, please contact us immediately. We have a backup option to provide you with a temporary API key for the duration of this assignment.\n",
        "\n",
        "> **Security Warning:** Your API key is sensitive information. Never share it publicly or commit it to version control systems.\n",
        "\n",
        "After obtaining your API key, you'll use it in the code as shown in the next section. Remember to replace 'your-api-key-here' with your actual API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "izf3SzUwpwxU"
      },
      "outputs": [],
      "source": [
        "# Set your OpenAI API key here\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR 0PENAI API_KEY HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INLhtQOmaefr"
      },
      "source": [
        "# **Function to analyze input data for potential keywords**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ScXGHLfHamQu"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "# Function to detect types of personal data\n",
        "def detect_data_types(text):\n",
        "    data_types = []\n",
        "    patterns = {\n",
        "      \"name\": r\"\\b(?:Mr\\.|Ms\\.|Dr\\.|[A-Z][a-z]+(?:\\s[A-Z][a-z]+){1,2})\\b\",\n",
        "      \"date\": r\"\\b(\\d{1,2}\\s\\w+\\s\\d{4})|(\\w+\\s\\d{1,2},\\s\\d{4})\\b\",\n",
        "      \"address\": r\"\\b\\d+\\s[A-Za-z\\s]+\\s(?:Street|St|Avenue|Ave|Boulevard|Blvd|Road|Rd|Lane|Ln|Drive|Dr)\\b\",\n",
        "      \"contact\": r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b|\\b\\d{10}|\\b\\d{3}[-.\\s]??\\d{3}[-.\\s]??\\d{4}\\b\",\n",
        "      \"code\": r\"\\bcode\\s\\w+\\b\"  # Capture codes (like DAWSON23)\n",
        "  }\n",
        "\n",
        "    for data_type, pattern in patterns.items():\n",
        "        if re.search(pattern, text):\n",
        "            data_types.append(data_type)\n",
        "    return data_types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfhinP6naaEH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GvQTl0Ra66n"
      },
      "source": [
        "# **Set dynamic system prompt based on detected data types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "urNzxXqua_S6"
      },
      "outputs": [],
      "source": [
        "# Dynamic system prompt creation based on detected data types\n",
        "def set_dynamic_system_prompt(data_types):\n",
        "    prompt = \"You are a data masking assistant. Please replace all sensitive personal data with the placeholder [PERSONAL].\"\n",
        "    for data_type in data_types:\n",
        "        prompt += f\"\\n- Mask {data_type} with [PERSONAL].\"\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSY2FGM0g1ik"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M6jUqTngg3ZH"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")  # Load English NLP model\n",
        "\n",
        "def mask_names(text):\n",
        "    doc = nlp(text)\n",
        "    for token in doc:\n",
        "        if token.ent_type_ == \"PERSON\":  # Check if the token is identified as a person\n",
        "            text = text.replace(token.text, '[PERSONAL]')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q194CsCuhCWD"
      },
      "outputs": [],
      "source": [
        "def mask_addresses(text):\n",
        "    # Example regex patterns for various address formats\n",
        "    address_patterns = [\n",
        "        r'\\d{1,3}\\s\\w+\\s\\w+(\\s\\w+)?',  # Simple street address\n",
        "        r'\\d+\\s[a-zA-Z\\s&]+(?:,\\s[a-zA-Z\\s&]+)?',  # Addresses with city/state\n",
        "        r'Near\\s\\w+',  # Proximity indicators\n",
        "        r'\\d+\\s[A-Za-z]+\\sSt',  # Specific patterns (Street)\n",
        "    ]\n",
        "\n",
        "    for pattern in address_patterns:\n",
        "        text = re.sub(pattern, '[PERSONAL]', text)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HJWAX5MmhGtB"
      },
      "outputs": [],
      "source": [
        "def mask_indirect_references(text):\n",
        "    indirect_references = [\n",
        "        r'\\bmy friend\\b',  # Example indirect reference\n",
        "        r'\\bthe patient\\b',\n",
        "        r'\\bmy colleague\\b',\n",
        "        r'\\bthe teacher\\b'\n",
        "    ]\n",
        "\n",
        "    for ref in indirect_references:\n",
        "        text = re.sub(ref, '[PERSONAL]', text)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv6gF0RPwF3Y"
      },
      "source": [
        "## Basic API Interaction\n",
        "\n",
        "In the context of using the OpenAI API, we need to understand how to structure our requests:\n",
        "\n",
        "* `system_prompt`: This sets the overall context or instructions for the model. It's like giving the model its role or job description.\n",
        "* `user_prompt`: This contains the specific input or task for the model to process. In our case, it will contain the text to be masked.\n",
        "* `temperature`: Controls randomness in the output. Lower values (e.g., 0.1) make the output more deterministic, while higher values introduce more randomness.\n",
        "* `max_tokens`: The maximum number of tokens the model will generate.\n",
        "\n",
        "Let's set up the initial prompts and try to mask personal data in this wedding invitation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ytmG_7n1J2L",
        "outputId": "a794009e-325f-4f17-e669-4d0d518ab756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Masked Text:\n",
            "INVITATION\n",
            "\n",
            "You are cordially invited [PERSONAL]\n",
            "[PERSONAL] Louise Parker\n",
            "&\n",
            "[PERSONAL] James Dawson\n",
            "\n",
            "Date: [PERSONAL][PERSONAL][PERSONAL]\n",
            "Time: [PERSONAL][PERSONAL]\n",
            "Venue: [PERSONAL][PERSONAL][PERSONAL][PERSONAL][PERSONAL][PERSONAL]\n",
            "\n",
            "RSVP [PERSONAL]\n",
            "Reception [PERSONAL]\n",
            "Book your stay using [PERSONAL]\n",
            "\n",
            "Wedding registry: www.weddingwishes.com/EmmaAndChris\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()\n",
        "\n",
        "# System prompt for the API call\n",
        "system_prompt = \"You are a personal data masking assistant. Your task is to identify and mask personal information in the provided text with '[PERSONAL]'.\"\n",
        "\n",
        "# Function to mask personal data\n",
        "def mask_personal_data(text):\n",
        "    # Mask all words after specific keywords until the next newline\n",
        "    keywords = r'\\b(?:by|at|to|code|or|with|for|in|from|about|as|like|during|between)\\s(.*?)(?=\\n|$)'\n",
        "    text = re.sub(keywords, r'[PERSONAL]', text)  # Mask after keywords\n",
        "\n",
        "    # Mask all words after ':' until the newline\n",
        "    text = re.sub(r'(?<=:\\s)(.*?)(?=\\n)', lambda m: '[PERSONAL]' * len(m.group(0).split()), text)  # Mask after colons\n",
        "\n",
        "    # Mask names (placeholder names here for simplicity)\n",
        "    text = re.sub(r'\\b(?:Emma|Christopher|John|Mary|Jane|Doe)\\b', '[PERSONAL]', text)  # Known names\n",
        "    # Mask dates in various formats\n",
        "    text = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{4}', '[PERSONAL]', text)  # MM/DD/YYYY\n",
        "    text = re.sub(r'\\b\\d{1,2} [A-Za-z]+ \\d{4}\\b', '[PERSONAL]', text)  # Specific date formats\n",
        "    # Mask phone numbers\n",
        "    text = re.sub(r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b', '[PERSONAL]', text)  # Phone numbers\n",
        "    # Mask email addresses\n",
        "    text = re.sub(r'\\b\\w+@\\w+\\.\\w+\\b', '[PERSONAL]', text)  # Email addresses\n",
        "    # Mask addresses\n",
        "    text = re.sub(r'(\\d{1,3}\\s\\w+(\\s\\w+)*,?\\s\\w+)', '[PERSONAL]', text)  # Addresses\n",
        "\n",
        "    # Make API call\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    # Extract and return masked text\n",
        "    masked_text = response.choices[0].message.content\n",
        "    return masked_text\n",
        "\n",
        "# Function to run tests\n",
        "def run_tests(test_cases):\n",
        "    results = {}\n",
        "\n",
        "    for case_name, text in test_cases.items():\n",
        "        masked_text = mask_personal_data(text)\n",
        "        results[case_name] = masked_text\n",
        "\n",
        "    return results\n",
        "\n",
        "# Sample user input\n",
        "user_text = \"\"\"\n",
        "INVITATION\n",
        "\n",
        "You are cordially invited to celebrate the wedding of\n",
        "Emma Louise Parker\n",
        "&\n",
        "Christopher James Dawson\n",
        "\n",
        "Date: August 15, 2023\n",
        "Time: 3:00 PM\n",
        "Venue: Rosewood Gardens, 1515 Rose Lane, Sunnyville\n",
        "\n",
        "RSVP by July 1st to emmaandchris@lovebirds.com or 555-789-0123\n",
        "Reception to follow at Sunnyville Grand Hotel\n",
        "Book your stay using code DAWSON23 for a special rate\n",
        "\n",
        "Wedding registry: www.weddingwishes.com/EmmaAndChris\n",
        "\"\"\".strip()\n",
        "\n",
        "# Run the masking function\n",
        "masked_output = mask_personal_data(user_text)\n",
        "print(\"Masked Text:\")\n",
        "print(masked_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE8XIpf6_h6Z"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg9k_sNB5Lmt"
      },
      "source": [
        "> **Think about it:** How does the structure of `system_prompt` and `user_prompt` affect the model's understanding of the task? What types of personal information should be masked in this context?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCNfptuuetFH"
      },
      "source": [
        "# **Test Cases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nZ7wXArKewii"
      },
      "outputs": [],
      "source": [
        "test_cases = {\n",
        "    \"wedding_invitation\": \"\"\"\n",
        "        You are cordially invited to celebrate the wedding of Emma Louise Parker & Christopher James Dawson.\n",
        "        Date: August 15, 2023\n",
        "        Time: 3:00 PM\n",
        "        Venue: Rosewood Gardens, 1515 Rose Lane, Sunnyville.\n",
        "        RSVP by July 1st to emmaandchris@lovebirds.com or 555-789-0123.\n",
        "        Reception to follow at Sunnyville Grand Hotel.\n",
        "        Book your stay using code DAWSON23 for a special rate.\n",
        "    \"\"\",\n",
        "    \"cv\": \"\"\"\n",
        "        John Doe\n",
        "        123 Main St, Springfield, IL 62704\n",
        "        (555) 123-4567\n",
        "        john.doe@example.com\n",
        "        Experience:\n",
        "        - Software Engineer at Tech Solutions (2018-present)\n",
        "        - Intern at XYZ Corp (2017-2018)\n",
        "    \"\"\",\n",
        "    \"email_correspondence\": \"\"\"\n",
        "        Hi Jane,\n",
        "        I hope you're doing well. I wanted to follow up on our last conversation regarding the project due on April 15, 2024.\n",
        "        Please send me the documents at jane.doe@company.com or call me at (555) 987-6543.\n",
        "        Thanks,\n",
        "        John\n",
        "    \"\"\",\n",
        "    \"medical_record\": \"\"\"\n",
        "        Patient Name: Mary Smith\n",
        "        DOB: 01/10/1985\n",
        "        Appointment Date: 11/02/2024\n",
        "        Diagnosis: Hypertension\n",
        "        Doctor's Contact: dr.jones@hospital.com\n",
        "    \"\"\",\n",
        "    \"social_media_post\": \"\"\"\n",
        "        Just got back from an amazing trip to Bali with my best friend Sarah!\n",
        "        Can’t believe it’s already November 4, 2023. Can’t wait to share the photos!\n",
        "    \"\"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lON3BgOce5D5"
      },
      "source": [
        "# **Running Test Cases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P0JAgkHftCA",
        "outputId": "f085eaaf-d724-4d6a-c164-20428527c6f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- wedding_invitation ---\n",
            "You are cordially invited [PERSONAL]\n",
            "Date: [PERSONAL][PERSONAL][PERSONAL]\n",
            "Time: [PERSONAL][PERSONAL]\n",
            "Venue: [PERSONAL][PERSONAL][PERSONAL][PERSONAL][PERSONAL][PERSONAL]\n",
            "RSVP [PERSONAL]\n",
            "Reception [PERSONAL]\n",
            "Book your stay using [PERSONAL]\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- cv ---\n",
            "[PERSONAL] [PERSONAL]\n",
            "[PERSONAL], IL 62704\n",
            "(555) 123-4567\n",
            "john.[PERSONAL]\n",
            "Experience:\n",
            "[PERSONAL][PERSONAL][PERSONAL][PERSONAL]\n",
            "- Intern [PERSONAL]\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- email_correspondence ---\n",
            "Hi [PERSONAL],\n",
            "I hope you're doing well. I wanted [PERSONAL]\n",
            "Please send me the documents [PERSONAL]\n",
            "Thanks,\n",
            "[PERSONAL]\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- medical_record ---\n",
            "Patient Name: [PERSONAL][PERSONAL]  \n",
            "DOB: [PERSONAL]  \n",
            "Appointment Date: [PERSONAL]  \n",
            "Diagnosis: [PERSONAL]  \n",
            "Doctor's Contact: [PERSONAL]  \n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "--- social_media_post ---\n",
            "Just got back [PERSONAL]\n",
            "Can’t believe it’s already November 4, 2023. Can’t wait [PERSONAL]\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to run masking tests on a set of input test cases\n",
        "def run_tests(test_cases):\n",
        "    # Initialize an empty dictionary to store test results\n",
        "    results = {}\n",
        "\n",
        "    # Loop through each test case in the provided dictionary\n",
        "    for case_name, text in test_cases.items():\n",
        "        # Apply the mask_personal_data function to mask sensitive data in the text\n",
        "        masked_text = mask_personal_data(text)\n",
        "        # Store the masked output in the results dictionary, using the case name as the key\n",
        "        results[case_name] = masked_text\n",
        "\n",
        "    # Return the dictionary containing masked results for each test case\n",
        "    return results\n",
        "\n",
        "# Execute the run_tests function with test cases and store the masked outputs\n",
        "masked_results = run_tests(test_cases)\n",
        "\n",
        "# Print the masked output for each test case in a formatted way\n",
        "for case_name, masked_text in masked_results.items():\n",
        "    # Print the name of the test case\n",
        "    print(f\"--- {case_name} ---\")\n",
        "    # Print the masked text\n",
        "    print(masked_text)\n",
        "    # Print a separator line for readability between test cases\n",
        "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5SNsrtjwYSm"
      },
      "source": [
        "## Your Task: Develop an Advanced Personal Data Masking\n",
        "\n",
        "Now that you've seen a basic example, your task is to develop a more advanced masking system using the `gpt-3.5-turbo` model. Your system should be able to handle various types of documents and effectively mask different kinds of personal information.\n",
        "Here are the key aspects you need to consider:\n",
        "\n",
        "1. **Prompt Engineering:** Experiment with different system and user messages to improve masking accuracy. Consider what specific instructions might help the model identify and replace all types of personal information.\n",
        "\n",
        "1. **Parameter Tuning:** Explore how different parameters like `temperature`, `max_tokens`, or even `top_p`, `frequency_penalty`, and `presence_penalty` affect the output. Find the optimal balance for consistent and accurate masking. See the parameters explanation in the OpenAI API reference: https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "1. **Handling Different Document Types:** Your system should be able to mask various document types, such as:\n",
        "  * Resumes/CVs\n",
        "  * Email correspondences\n",
        "  * Medical records\n",
        "  * Social media posts\n",
        "  * News articles\n",
        "  * etc.\n",
        "\n",
        "1. **Edge Cases:** Consider how your system might handle edge cases, such as:\n",
        "  * Names that are also common words\n",
        "  * Addresses with non-standard formats\n",
        "  * Indirect personal references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj5zf7xBH95J"
      },
      "source": [
        "## Evaluation Criteria\n",
        "Your masking system will be evaluated based on the following criteria:\n",
        "1. Accuracy of masking across different types of personal information\n",
        "1. Diversity and creativity of identified input scenarios and personal data types\n",
        "1. Handling of edge cases and challenging scenarios\n",
        "1. Creativity and effectiveness of prompt engineering\n",
        "1. Thoughtfulness of parameter choices and their justification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olcp2zSXxKbZ"
      },
      "source": [
        "## Expected Output\n",
        "Your final submission should include:\n",
        "\n",
        "1. The complete notebook with your final, optimized version of the code, including:\n",
        "  * The most effective system prompt and user prompt you developed\n",
        "  * The optimal configuration parameters you found\n",
        "  * Any additional functions or modifications you made to improve masking\n",
        "1. A brief reflection and analysis addressing the following points:\n",
        "  * What combination of prompts and parameters yielded the best results? Why do you think this configuration was most effective?\n",
        "  * What were the main challenges in achieving consistent masking across different types of text?\n",
        "  * Imagine you need to evaluate 100 different personal data masking systems like yours, each tested on 100 diverse input documents. How would you design an automated evaluation process to efficiently compare and rank these systems? What methods or techniques would you consider to efficiently assess the performance of these various personal data masking systems?\n",
        "1. Enumeration of the input scenarios and personal data types you considered, including non-obvious cases\n",
        "\n",
        "> **Important:** Ensure that your notebook is runnable and reproducible. Before submitting, click the \"Share\" button in the top-right corner, set the access to \"Anyone with the link\" and permissions to \"Viewer\". Copy the sharing link and include it with your submission. This allows reviewers to access your final work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uRMbhRaISBd"
      },
      "source": [
        "## Time Management\n",
        "While there is no strict deadline, we recommend allocating approximately 4-6 hours for this assignment. This should allow sufficient time for experimentation, analysis, and reflection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5m-NLJQ1LSV"
      },
      "source": [
        "## Conclusion\n",
        "This assignment tasks you with building a personal data masking system using the GPT-3.5-turbo model. You'll be working directly with the OpenAI API, crafting prompts, and developing strategies to handle various types of personal information across different document formats.\n",
        "\n",
        "While the core task is clear, the implementation is open-ended. We're interested in your approach to prompt engineering, your creativity in generating diverse evaluation cases, and your insights into the strengths and limitations of LLM-based data processing. We're curious to see your solution."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
